#配置spark相关参数
spark.worker.timeout="500"
spark.rpc.askTimeout="600s"
spark.network.timeoout="600s"
spark.cores.max="10"
spark.task.maxFailures="5"
spark.speculation="true"
spark.driver.allowMutilpleContext="true"
spark.serializer="org.apache.spark.serializer.KryoSerializer"
spark.buffer.pageSize="200m"
spark.streaming.checkpointdir="hdfs://node01:8020/streaming"
spark.streaming.kafka.maxRatePerPartition="1000"
#因为首次启动JOB的时候，由于冷启动会造成内存使用太大，为了防止这种情况出现，限制首次处理的数据量
spark.streaming.backpressure.enabled=true
spark.streaming.backpressure.initialRate="10"

#起始符 4字节
initial.character="4"

#Hbase的配置
hbase.zookeeper.quorum="node01,node02,node03"#zookeeper地址
hbase.master="node01:60000"#Hmaster地址
hbase.zookeeper.property.clientPort="2181"#端口
hbase.rpc.timeout="600000"
hbase.client.operator.timeout="600000"
hbase.client.scanner.timeout.period="600000"

#Kafka的配置
auto.offset.reset="latest"

#列族
heart.table.columnFamily="MM"#hbase列族

#自定义数据源的别名
sparksql_table_schema="sparksql_table_schema"
hbase_table_name="hbase_table_name"
hbase_table_schema="hbase_table_schema"
#val outputUri="mongodb://test:test@47.99.187.146:27017/och_test.hot1"

hdfs.host="hdfs://node01:8020/hfile/"



